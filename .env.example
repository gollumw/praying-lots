# Ollama 本機 LLM（抽籤結果與 AI 聊天用）
# 部署前請先啟動：ollama serve
# 並確保已拉取模型：ollama pull gemma3:27b

OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:27b
